data = dict(model_name_or_path='decapoda-research/llama-7b-hf',
            trust_remote_code=False,
            use_auth_token=False,
            eval_dataset_size=1024,
            max_train_samples=None,
            max_eval_samples=1000,
            source_max_len=16,
            target_max_len=512,
            dataset='alpaca',
            dataset_format=None,
            output_dir='./output/guanaco-7b',
            overwrite_output_dir=False,
            do_train=True,
            do_eval=True,
            do_predict=False,
            evaluation_strategy='steps',
            prediction_loss_only=False,
            per_device_train_batch_size=1,
            per_device_eval_batch_size=1,
            per_gpu_train_batch_size=None,
            per_gpu_eval_batch_size=None,
            gradient_accumulation_steps=16,
            eval_accumulation_steps=None,
            eval_delay=0,
            learning_rate=0.0002,
            weight_decay=0.0,
            adam_beta1=0.9,
            adam_beta2=0.999,
            adam_epsilon=1e-08,
            max_grad_norm=0.3,
            num_train_epochs=3.0,
            max_steps=1875,
            lr_scheduler_type='constant',
            warmup_ratio=0.03,
            warmup_steps=0,
            log_level='passive',
            log_level_replica='warning',
            log_on_each_node=True,
            logging_dir='./output/guanaco-7b/runs/Jun15_16-46-01_P920',
            logging_strategy='steps',
            logging_first_step=False,
            logging_steps=10,
            logging_nan_inf_filter=True,
            save_strategy='steps',
            save_steps=500,
            save_total_limit=40,
            save_safetensors=False,
            save_on_each_node=False,
            no_cuda=False,
            use_mps_device=False,
            seed=0,
            data_seed=42,
            jit_mode_eval=False,
            use_ipex=False,
            bf16=False,
            fp16=True,
            fp16_opt_level='O1',
            half_precision_backend='auto',
            bf16_full_eval=False,
            fp16_full_eval=False,
            tf32=None,
            local_rank=0,
            ddp_backend=None,
            tpu_num_cores=None,
            tpu_metrics_debug=False,
            debug=[],
            dataloader_drop_last=False,
            eval_steps=187,
            dataloader_num_workers=3,
            past_index=-1,
            run_name='./output/guanaco-7b',
            disable_tqdm=False,
            remove_unused_columns=False,
            label_names=None,
            load_best_model_at_end=False,
            metric_for_best_model=None,
            greater_is_better=None,
            ignore_data_skip=False,
            sharded_ddp=[],
            fsdp=[],
            fsdp_min_num_params=0,
            fsdp_config={
                'fsdp_min_num_params': 0,
                'xla': False,
                'xla_fsdp_grad_ckpt': False
            },
            fsdp_transformer_layer_cls_to_wrap=None,
            deepspeed=None,
            label_smoothing_factor=0.0,
            optim='paged_adamw_32bit',
            optim_args=None,
            adafactor=False,
            group_by_length=True,
            length_column_name='length',
            report_to=[],
            ddp_find_unused_parameters=None,
            ddp_bucket_cap_mb=None,
            dataloader_pin_memory=True,
            skip_memory_metrics=True,
            use_legacy_prediction_loop=False,
            push_to_hub=False,
            resume_from_checkpoint=None,
            hub_model_id=None,
            hub_strategy='every_save',
            hub_token=None,
            hub_private_repo=False,
            gradient_checkpointing=True,
            include_inputs_for_metrics=False,
            fp16_backend='auto',
            push_to_hub_model_id=None,
            push_to_hub_organization=None,
            push_to_hub_token=None,
            mp_parameters='',
            auto_find_batch_size=False,
            full_determinism=False,
            torchdynamo=None,
            ray_scope='last',
            ddp_timeout=1800,
            torch_compile=False,
            torch_compile_backend=None,
            torch_compile_mode=None,
            xpu_backend=None,
            sortish_sampler=False,
            predict_with_generate=False,
            generation_max_length=None,
            generation_num_beams=None,
            cache_dir=None,
            train_on_source=False,
            mmlu_split='eval',
            mmlu_dataset='mmlu-fs',
            do_mmlu_eval=False,
            max_mmlu_samples=None,
            mmlu_source_max_len=2048,
            full_finetune=False,
            adam8bit=False,
            double_quant=True,
            quant_type='nf4',
            bits=4,
            lora_r=64,
            lora_alpha=16.0,
            lora_dropout=0.1,
            max_memory_MB=80000,
            distributed_state='',
            _n_gpu=1,
            __cached__setup_devices='',
            deepspeed_plugin=None)
